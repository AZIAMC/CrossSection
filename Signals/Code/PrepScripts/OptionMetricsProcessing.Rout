
R version 4.1.2 (2021-11-01) -- "Bird Hippie"
Copyright (C) 2021 The R Foundation for Statistical Computing
Platform: x86_64-redhat-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> ### ENVIRONMENT ###
> rm(list = ls())
> 
> path_dl_me = '~/data_prep/'
> 
> dir.create(path_dl_me)
Warning message:
In dir.create(path_dl_me) : '/home/frb/chen1678/data_prep' already exists
> 
> library(RPostgres)
> library(tidyverse)
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──
✔ ggplot2 3.3.5     ✔ purrr   0.3.4
✔ tibble  3.1.6     ✔ dplyr   1.0.7
✔ tidyr   1.1.4     ✔ stringr 1.4.0
✔ readr   2.1.1     ✔ forcats 0.5.1
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
> library(lubridate)

Attaching package: ‘lubridate’

The following objects are masked from ‘package:base’:

    date, intersect, setdiff, union

> 
> # heads up: this assumes (1) running on wrds server and (2) pgpass is set up following this:
> # https://wrds-www.wharton.upenn.edu/pages/support/programming-wrds/programming-r/r-from-the-web/
> wrds <- dbConnect(Postgres(),
+                   host='wrds-pgdata.wharton.upenn.edu',
+                   port=9737,
+                   dbname='wrds',
+                   sslmode='require')
> 
>   # debugging
>   # wrds <- dbConnect(Postgres(),
>   #                   host='wrds-pgdata.wharton.upenn.edu',
>   #                   port=9737,
>   #                   dbname='wrds',
>   #                   sslmode='require',
>   #                   user='chen1678')
> 
> numRowsToPull = 20 # for debugging
> 
> 
> # Download and process options data
> # this code is so involved I decided to make it separate - Andrew 2019 10
> # Whole thing takes about 3 hours to run
> 
> ## === Options Prep 1/3: Smile Slope a.k.a. Slope (Yan) code ====
> # takes about 60 min
> 
> # set up loop
> rm(list = ls(pattern = 'temp'))
> 
> vsurf_tables = dbGetQuery(
+   wrds, "
+   SELECT table_name 
+       FROM information_schema.tables
+       WHERE table_schema = 'optionm' 
+         AND table_name like 'vsurfd%'
+   "
+   )
> yearlist = substr(vsurf_tables$table_name, 7,12)
> 
> # prepare list of data frames
> slopemany = list()
> 
> # Setup query
> # adding the filter for deltas and duration speeds query up a lot I think
>   queryprestring = paste0("select a.secid, a.date, a.days, a.cp_flag, a.delta "
+                           ,",a.impl_volatility "
+                          ,"from optionm.vsurfd")
>   querypoststring = paste0(
+       " as a "
+      ,"where (a.impl_volatility != 'NaN')"
+      ," and ((a.cp_flag = \'C\' and a.delta = 50)  "
+      ,"  or (a.cp_flag = \'P\' and a.delta = -50)) "
+      ," and a.days = 30 "
+      ," and extract(day from a.date) >= 23 "
+   )   
> 
> print("Calculating Smile Slope a.k.a. Slope (Yan) year by year")
[1] "Calculating Smile Slope a.k.a. Slope (Yan) year by year"
> i = 1
> for (year in yearlist) {
+   print(Sys.time())
+   start_time = Sys.time()
+   print(year)
+   
+   # download data
+   res = dbSendQuery(
+     conn=wrds,
+     statement=paste0(queryprestring,year,querypoststring)
+   )
+   tempd <- dbFetch(res, numRowsToPull)
+   tempd = tempd %>% mutate(time_avail_m = ceiling_date(date, unit = "month")-1)  
+   dbClearResult(res)
+   
+   # take last obs each month
+   tempm = tempd %>%
+       group_by(secid, cp_flag, time_avail_m) %>%      
+       arrange(secid, cp_flag, date) %>%
+       filter(row_number()==n()) %>%
+       rename(impl_vol = impl_volatility)
+   
+   # compute spread
+   tempmwide = tempm %>% select(secid,time_avail_m,cp_flag,impl_vol) %>%
+       spread(cp_flag, impl_vol)
+   tempmwide = tempmwide %>% mutate(slope = P-C) %>%
+     select(secid, time_avail_m, slope)
+   
+   # save and advance  
+   slopemany[[i]] = tempmwide
+   i = i + 1
+   
+   end_time <- Sys.time()
+   print(end_time - start_time)    
+   
+ }  # end Slope loop over years
[1] "2022-02-09 10:22:33 EST"
[1] "1996"
Time difference of 0.1625454 secs
[1] "2022-02-09 10:22:34 EST"
[1] "1997"
Time difference of 0.04254937 secs
[1] "2022-02-09 10:22:34 EST"
[1] "1998"
Time difference of 0.04417086 secs
[1] "2022-02-09 10:22:34 EST"
[1] "1999"
Time difference of 0.04591274 secs
[1] "2022-02-09 10:22:34 EST"
[1] "2000"
Time difference of 0.04419374 secs
[1] "2022-02-09 10:22:34 EST"
[1] "2001"
Time difference of 0.0442245 secs
[1] "2022-02-09 10:22:34 EST"
[1] "2002"
Time difference of 0.04409909 secs
[1] "2022-02-09 10:22:34 EST"
[1] "2003"
Time difference of 0.0464747 secs
[1] "2022-02-09 10:22:34 EST"
[1] "2004"
Time difference of 0.05018997 secs
[1] "2022-02-09 10:22:34 EST"
[1] "2005"
Time difference of 0.0422318 secs
[1] "2022-02-09 10:22:34 EST"
[1] "2006"
Time difference of 0.04252696 secs
[1] "2022-02-09 10:22:34 EST"
[1] "2007"
Time difference of 0.0429616 secs
[1] "2022-02-09 10:22:34 EST"
[1] "2008"
Time difference of 0.04101348 secs
[1] "2022-02-09 10:22:34 EST"
[1] "2009"
Time difference of 0.04515123 secs
[1] "2022-02-09 10:22:34 EST"
[1] "2010"
Time difference of 0.0426271 secs
[1] "2022-02-09 10:22:34 EST"
[1] "2011"
Time difference of 0.044034 secs
[1] "2022-02-09 10:22:34 EST"
[1] "2012"
Time difference of 0.04531646 secs
[1] "2022-02-09 10:22:34 EST"
[1] "2013"
Time difference of 0.06769681 secs
[1] "2022-02-09 10:22:34 EST"
[1] "2014"
Time difference of 0.04173851 secs
[1] "2022-02-09 10:22:34 EST"
[1] "2015"
Time difference of 0.0497129 secs
[1] "2022-02-09 10:22:35 EST"
[1] "2016"
Time difference of 0.04375648 secs
[1] "2022-02-09 10:22:35 EST"
[1] "2017"
Time difference of 0.04182601 secs
[1] "2022-02-09 10:22:35 EST"
[1] "2018"
Time difference of 0.04516125 secs
[1] "2022-02-09 10:22:35 EST"
[1] "2019"
Time difference of 0.04541159 secs
[1] "2022-02-09 10:22:35 EST"
[1] "2020"
Time difference of 0.04465914 secs
> 
> # finally, merge years together
> slopeall = do.call(rbind,slopemany)
> 
> ## === Options Prep 2/3: Smirk a.k.a. Skew1 (Xing Zhang, Zhao 2010) ====
> # may take 2 hours
> 
> # set up loop
> # note this loop re-uses the yearlist from Options Prep 1/3
> rm(list = ls(pattern = 'temp'))
> skewmany = list()
> 
> print("Calculating Smirk aka Skew1 year by year")
[1] "Calculating Smirk aka Skew1 year by year"
> i = 1
> for (year in yearlist) {
+   print(Sys.time())
+   start_time = Sys.time()
+   print(year)     
+   
+   ## download daily data with lots of filters
+   res <- dbSendQuery(
+     wrds
+     ,paste0("
+   select a.secid, a.date, a.close 
+   ,b.optionid, b.cp_flag, b.strike_price, b.impl_volatility "
+   ,"from optionm.secprd"
+   ,year
+   ," as a left join optionm.opprcd"
+   ,year
+   ," as b   
+   on a.secid = b.secid and a.date = b.date
+   where (b.strike_price != 'NaN') and (b.impl_volatility != 'NaN')
+   and (b.exdate - a.date >= 10) and (b.exdate - a.date <= 60)
+   and (
+     (b.cp_flag = 'C' and b.strike_price/1000/a.close > 0.95 and b.strike_price/1000/a.close < 1.05)
+     or
+     (b.cp_flag = 'P' and b.strike_price/1000/a.close < 0.95 and b.strike_price/1000/a.close > 0.80)
+     )
+   and a.volume > 0
+   and b.impl_volatility > 0.03 and b.impl_volatility < 2.0
+   and (b.best_bid+b.best_offer)/2 > 0.125
+   and b.open_interest > 0 and b.volume != 'NaN'    
+   and extract(day from a.date) >= 23
+     ")
+   )    
+   tempd <- dbFetch(res, numRowsToPull)
+   
+   ## find "money-ness-based skew" daily
+   tempcall = tempd  %>%
+     filter(cp_flag == 'C') %>%
+     group_by(secid,date) %>%
+     arrange(abs(strike_price/1000/close-1)) %>%
+     filter(row_number()==1)    
+   tempput = tempd  %>%
+     filter(cp_flag == 'P') %>%        
+     group_by(secid,date) %>%
+     arrange(desc(strike_price/1000/close)) %>%
+     filter(row_number()==1)
+   tempd2 = inner_join(tempcall,tempput,by=c("secid","date"),suffix=c(".call",".put")) %>%
+     mutate(Skew1 = impl_volatility.put - impl_volatility.call)
+   
+   
+   ## average within month (actually last week of the month, see sql query)
+   tempm = tempd2 %>%
+     mutate(time_avail_m = ceiling_date(date, unit = "month")-1) %>%
+     group_by(secid,time_avail_m) %>%
+     summarize(Skew1 = mean(Skew1))
+   
+   ## append
+   skewmany[[i]] = tempm
+   i = i + 1
+   
+   end_time <- Sys.time()
+   print(end_time - start_time)  
+   
+   
+ }  # end Skew loop over years
[1] "2022-02-09 10:22:35 EST"
[1] "1996"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 4.070335 secs
[1] "2022-02-09 10:22:39 EST"
[1] "1997"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 5.354187 secs
[1] "2022-02-09 10:22:44 EST"
[1] "1998"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 6.098278 secs
[1] "2022-02-09 10:22:51 EST"
[1] "1999"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 6.664698 secs
[1] "2022-02-09 10:22:57 EST"
[1] "2000"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 8.432792 secs
[1] "2022-02-09 10:23:06 EST"
[1] "2001"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 7.519427 secs
[1] "2022-02-09 10:23:13 EST"
[1] "2002"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 7.599219 secs
[1] "2022-02-09 10:23:21 EST"
[1] "2003"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 7.717503 secs
[1] "2022-02-09 10:23:28 EST"
[1] "2004"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 12.11986 secs
[1] "2022-02-09 10:23:41 EST"
[1] "2005"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 11.23714 secs
[1] "2022-02-09 10:23:52 EST"
[1] "2006"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 9.905033 secs
[1] "2022-02-09 10:24:02 EST"
[1] "2007"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 13.54851 secs
[1] "2022-02-09 10:24:15 EST"
[1] "2008"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 0.09416986 secs
[1] "2022-02-09 10:24:15 EST"
[1] "2009"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 0.04579735 secs
[1] "2022-02-09 10:24:15 EST"
[1] "2010"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 0.05575657 secs
[1] "2022-02-09 10:24:15 EST"
[1] "2011"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 0.04897952 secs
[1] "2022-02-09 10:24:15 EST"
[1] "2012"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 0.04874039 secs
[1] "2022-02-09 10:24:16 EST"
[1] "2013"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 0.05052185 secs
[1] "2022-02-09 10:24:16 EST"
[1] "2014"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 0.05136776 secs
[1] "2022-02-09 10:24:16 EST"
[1] "2015"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 0.05621004 secs
[1] "2022-02-09 10:24:16 EST"
[1] "2016"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 0.06731176 secs
[1] "2022-02-09 10:24:16 EST"
[1] "2017"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 0.0511682 secs
[1] "2022-02-09 10:24:16 EST"
[1] "2018"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 0.05780983 secs
[1] "2022-02-09 10:24:16 EST"
[1] "2019"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 0.04689193 secs
[1] "2022-02-09 10:24:16 EST"
[1] "2020"
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
Time difference of 0.04656911 secs
There were 24 warnings (use warnings() to see them)
> 
> ## finally, merge years together
> skewall = do.call(rbind,skewmany)
> 
> 
> 
> ## === Options Prep 3/3: Volume
> rm(list = ls(pattern = 'temp'))
> 
> # option volume will later be merged with stock volume
> # about 2 min
> 
> # download volume data
> start_time = Sys.time()
> res = dbSendQuery(conn = wrds, statement = 
+                     "select a.*
+                       from optionm.opvold as a
+                       where a.cp_flag != 'NaN'"
+ ) 
Warning message:
In result_create(conn@ptr, statement, immediate) :
  Closing open result set, cancelling previous query
> tempd = res %>% dbFetch(n = numRowsToPull)
> tempd = tempd %>% mutate(time_avail_m = ceiling_date(date, unit = "month")-1)  
> dbClearResult(res)
> end_time = Sys.time()
> print(end_time-start_time)
Time difference of 0.03471017 secs
> 
> # sum volume over month by secid, month, calls and puts together
> tempm = tempd %>% group_by(secid, time_avail_m) %>%
+   summarize(optVolume = sum(volume))
`summarise()` has grouped output by 'secid'. You can override using the `.groups` argument.
> 
> # save
> optVolall = tempm
> 
> ## === Options Finish: merge datasets from Prep 1-3 and add linking info
> 
> rm(list = ls(pattern = 'temp'))
> rm(list = c("skewmany","slopemany"))
> 
> # download linking file
> start_time = Sys.time()
> optID = dbSendQuery(conn = wrds, statement = 
+                       "select distinct a.secid, a.ticker, a.cusip, a.effect_date
+                       from optionm.optionmnames as a
+                       "
+ ) %>% dbFetch(n = numRowsToPull)
> end_time = Sys.time()
> print(end_time-start_time)
Time difference of 17.25188 secs
> 
> # additional prep:
> # convert effective dates to monthly, find beginning and end dates
> # use year 3000 if no end date
> optID = optID %>% 
+   mutate(match_begin_m = ceiling_date(effect_date, unit = "month")-1)  %>%
+   arrange(secid,match_begin_m) %>%
+   group_by(secid) %>%
+   mutate(match_end_m = lead(match_begin_m, order_by=secid)) %>%
+   mutate(match_end_m = replace_na(match_end_m,as.Date("3000-01-01"))) %>%
+   select(-c("effect_date"))
> 
> 
> # merge skewall, slopeall, and optID into OptionMetrics
> OptionMetrics = full_join(skewall,slopeall,by= c("secid","time_avail_m"))
> OptionMetrics = full_join(OptionMetrics,optVolall,by= c("secid","time_avail_m"))
> temp1 = left_join(OptionMetrics,optID,by = "secid") 
> temp2 = temp1 %>% 
+   filter(time_avail_m >= match_begin_m & time_avail_m <= match_end_m )
> OptionMetrics = temp2 %>% select(-c("match_begin_m","match_end_m"))
> 
> # finally write to csv!
> data.table::fwrite(OptionMetrics,
+                    file = paste0(
+                        path_dl_me
+                        , 'OptionMetrics.csv'
+                        )
+                    )
> 
> proc.time()
   user  system elapsed 
  3.605   0.262 122.670 
